# backend/services/smart_ai_integration.py
# ×©×™×œ×•×‘ ××œ× ×©×œ ×”××¢×¨×›×ª ×”×—×›××” ×”×—×“×©×”

import os, requests, time
from sqlalchemy.orm import Session
from typing import Optional, Dict, Any, List

# ×™×™×‘×•× ×”×¨×›×™×‘×™× ×”×—×“×©×™× ×”××©×•×¤×¨×™×
from services.context_builder import build_supplier_context, build_owner_context
from services.context_to_prompt import (
    supplier_context_to_text, owner_context_to_text, 
    build_system_prompt, few_shots, join_prompt
)
from routers.intent_router import route_intent_and_answer
from models.user_model import User
from models.order_model import Order

# ---- ×ª×¦×•×¨×ª AI ××ª×§×“××ª ----
OLLAMA_BASE = os.getenv("OLLAMA_URL", "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:7b-instruct")

# ×”×’×“×¨×•×ª ××•×¤×˜×™××œ×™×•×ª ×œ×ª×’×•×‘×•×ª ×—×›××•×ª
SMART_GEN_OPTIONS = {
    "num_predict": int(os.getenv("AI_NUM_PREDICT", "300")),  # ×™×•×ª×¨ ××™×œ×™× ×œ×ª×©×•×‘×•×ª ×¢×©×™×¨×•×ª
    "num_ctx": int(os.getenv("AI_NUM_CTX", "4096")),        # ×™×•×ª×¨ ×–×™×›×¨×•×Ÿ ×œ×”×§×©×¨
    "temperature": float(os.getenv("AI_TEMPERATURE", "0.3")), # ×§×¦×ª ×™×•×ª×¨ ×™×¦×™×¨×ª×™×•×ª
    "top_p": float(os.getenv("AI_TOP_P", "0.85")),
    "repeat_penalty": float(os.getenv("AI_REPEAT_PENALTY", "1.15")),
    "top_k": int(os.getenv("AI_TOP_K", "40")),
}

# ---- Smart AI Service Class ----
class SmartAIService:
    """×©×™×¨×•×ª AI ×—×›× ×¢× ×™×›×•×œ×•×ª ××ª×§×“××•×ª"""
    
    def __init__(self, db: Session):
        self.db = db
        self._cache = {}
        self.cache_ttl = 45  # TTL ×§×¦×¨ ×™×•×ª×¨ ×œ××™×“×¢ ×¢×“×›× ×™
    
    def _fetch_user(self, uid: int) -> User | None:
        return self.db.query(User).filter(User.id == uid).first()

    def _resolve_role(self, user: User) -> str:
        """×–×™×”×•×™ ×ª×¤×§×™×“ ××©×•×¤×¨"""
        role = (getattr(user, "role", None) or getattr(user, "userType", "")).strip().lower()
        
        # ×ª××™×›×” ×‘×›××” ×•×¨×™××¦×™×•×ª
        supplier_roles = ["supplier", "×¡×¤×§", "2", "vendor", "wholesaler"]
        owner_roles = ["storeowner", "owner", "store_owner", "×‘×¢×œ ×—× ×•×ª", "1", "retailer", "client"]
        
        if role in supplier_roles:
            return "Supplier"
        elif role in owner_roles:
            return "StoreOwner"
        else:
            # × ×™×—×•×© ×—×›× ×œ×¤×™ × ×ª×•× ×™×
            orders_as_supplier = self.db.query(Order).filter(Order.supplier_id == user.id).count()
            orders_as_owner = self.db.query(Order).filter(Order.owner_id == user.id).count()
            
            if orders_as_supplier > orders_as_owner:
                return "Supplier"
            return "StoreOwner"

    def _ollama_generate_smart(self, prompt: str) -> str:
        """×§×¨×™××ª AI ××©×•×¤×¨×ª ×¢× error handling ×˜×•×‘ ×™×•×ª×¨"""
        url = f"{OLLAMA_BASE}/api/generate"
        payload = {
            "model": OLLAMA_MODEL, 
            "prompt": prompt, 
            "stream": False, 
            "options": SMART_GEN_OPTIONS
        }
        
        try:
            r = requests.post(url, json=payload, timeout=120)
            r.raise_for_status()
            response = (r.json() or {}).get("response", "").strip()
            
            if not response:
                return "×”××•×“×œ ×œ× ×”×—×–×™×¨ ×ª×©×•×‘×”. × ×¡×” ×œ× ×¡×— ××ª ×”×©××œ×” ××—×“×©."
            
            return response
            
        except requests.exceptions.Timeout:
            return "×”×ª×’×•×‘×” ××•×¨×›×ª ×–××Ÿ ×¨×‘. × ×¡×” ×©××œ×” ×¤×©×•×˜×” ×™×•×ª×¨."
        except requests.exceptions.ConnectionError:
            return "×œ× ××¦×œ×™×— ×œ×”×ª×—×‘×¨ ×œ××•×“×œ AI. ×‘×“×•×§ ×©×”×©×¨×ª Ollama ×¤×•×¢×œ."
        except Exception as e:
            return f"×©×’×™××” ×‘××•×“×œ AI: {str(e)}"

    def _get_cached_context(self, cache_key: str, builder_func) -> str:
        """×× ×’× ×•×Ÿ cache ×—×›× ×œ×‘×™×¦×•×¢×™× ×˜×•×‘×™× ×™×•×ª×¨"""
        now = time.time()
        if cache_key in self._cache:
            timestamp, data = self._cache[cache_key]
            if now - timestamp < self.cache_ttl:
                return data
        
        # ×‘× ×™×™×ª context ×—×“×©
        fresh_data = builder_func()
        self._cache[cache_key] = (now, fresh_data)
        
        # × ×™×§×•×™ cache ×™×©×Ÿ
        if len(self._cache) > 50:
            oldest_keys = sorted(self._cache.keys(), 
                               key=lambda k: self._cache[k][0])[:10]
            for k in oldest_keys:
                del self._cache[k]
        
        return fresh_data

    def get_smart_answer(self, question: str, user_id: int) -> str:
        """××—×–×™×¨ ×ª×©×•×‘×” ×—×›××” ×•××§×™×¤×”"""
        user = self._fetch_user(user_id)
        if not user:
            return "××©×ª××© ×œ× × ××¦× ×‘××¢×¨×›×ª."
        
        role = self._resolve_role(user)
        username = getattr(user, "username", "") or getattr(user, "contact_name", "")
        
        # ×©×œ×‘ 1: × ×¡×” ×ª×©×•×‘×” ×“×˜×¨××™× ×™×¡×˜×™×ª ××”×™×¨×” (Intent-based)
        intent_answer = route_intent_and_answer(self.db, role, user_id, question)
        if intent_answer:
            # ×”×•×¡×£ ××™×“×¢ × ×•×¡×£ ×× ×¨×œ×•×•× ×˜×™
            enhanced_answer = self._enhance_intent_answer(intent_answer, role, user_id, question)
            return enhanced_answer or intent_answer
        
        # ×©×œ×‘ 2: ×ª×©×•×‘×” ××‘×•×¡×¡×ª AI ×¢× context ××œ×
        return self._get_ai_answer(role, username, user_id, question)
    
    def _enhance_intent_answer(self, base_answer: str, role: str, user_id: int, question: str) -> Optional[str]:
        """××©×¤×¨ ×ª×©×•×‘×•×ª intent ×¢× ××™×“×¢ × ×•×¡×£ ×¨×œ×•×•× ×˜×™"""
        if not base_answer:
            return None
            
        # ×× ×”×ª×©×•×‘×” ×¢×œ ××•×¦×¨×™× ×¤×¢×™×œ×™×, ×”×•×¡×£ ×”××œ×¦×•×ª
        if "××•×¦×¨×™× ×¤×¢×™×œ×™×" in base_answer and role == "Supplier":
            # ×‘×“×•×§ ×× ×™×© ××•×¦×¨×™× ×‘××œ××™ × ××•×š
            from services.context_builder import fetch_supplier_products_detailed
            products = fetch_supplier_products_detailed(self.db, user_id, limit=100)
            low_stock = [p for p in products if p['is_active'] and p['stock'] <= max(p['min_quantity'], 5)]
            
            if low_stock:
                base_answer += f"\nğŸ’¡ ×™×© {len(low_stock)} ××•×¦×¨×™× ×‘××œ××™ × ××•×š - ×›×“××™ ×œ×¢×“×›×Ÿ!"
        
        # ×× ×”×ª×©×•×‘×” ×¢×œ ×”×–×× ×•×ª ×¤×ª×•×—×•×ª, ×”×•×¡×£ ×¤×¨×˜×™×
        elif "×”×–×× ×•×ª ×¤×ª×•×—×•×ª" in base_answer:
            if "××™×Ÿ ×”×–×× ×•×ª" not in base_answer:
                base_answer += "\nğŸ’¡ ×˜×™×¤: ×¢×“×›×Ÿ ×¡×˜×˜×•×¡×™× ×‘××•×¤×Ÿ ×§×‘×•×¢ ×œ×©×™×¤×•×¨ ×”×©×™×¨×•×ª."
        
        # ×× ×”×ª×©×•×‘×” ×¢×œ ××™×š ×œ×¢×©×•×ª ××©×”×•, ×”×•×¡×£ ×˜×™×¤×™×
        elif any(word in base_answer for word in ["×ª×¤×¨×™×˜ >", "××™×š ×œ", "× ×ª×™×‘:"]):
            base_answer += "\nâœ¨ ×–×§×•×§ ×œ×¢×–×¨×” × ×•×¡×¤×ª? ×©××œ ×¢×œ × ×•×©× ×¡×¤×¦×™×¤×™!"
        
        return base_answer

    def _get_ai_answer(self, role: str, username: str, user_id: int, question: str) -> str:
        """××—×–×™×¨ ×ª×©×•×‘×ª AI ××œ××” ×¢× context ×¢×©×™×¨"""
        
        # ×‘× ×™×™×ª context ××œ× ×¢× cache
        cache_key = f"context:{role}:{user_id}"
        
        if role == "Supplier":
            context_builder = lambda: build_supplier_context(self.db, user_id)
            text_builder = supplier_context_to_text
        else:
            context_builder = lambda: build_owner_context(self.db, user_id)
            text_builder = owner_context_to_text
        
        # ×§×‘×œ×ª context ×¢× cache
        full_context = self._get_cached_context(cache_key, context_builder)
        snapshot_text = text_builder(full_context)
        
        # ×‘× ×™×™×ª prompt ×—×›×
        permissions = full_context.get("permissions", [])
        system_prompt = build_system_prompt(role, username, permissions, snapshot_text)
        shots = few_shots(role)
        full_prompt = join_prompt(system_prompt, snapshot_text, shots, question)
        
        # ×§×¨×™××ª AI
        ai_response = self._ollama_generate_smart(full_prompt)
        
        # ×©×™×¤×•×¨ ×”×ª×©×•×‘×” ×œ×¤×™ ×”×§×©×¨
        return self._post_process_answer(ai_response, role, full_context, question)
    
    def _post_process_answer(self, answer: str, role: str, context: Dict, question: str) -> str:
        """×¢×™×‘×•×“ ×××—×•×¨ ×©×œ ×”×ª×©×•×‘×” ×œ×©×™×¤×•×¨ ××™×›×•×ª"""
        if not answer or "×œ× ×™×•×“×¢" in answer:
            return answer
        
        # ×”×•×¡×£ ×§×™×©×•×¨×™× ×œ×¤×¢×•×œ×•×ª ×¨×œ×•×•× ×˜×™×•×ª
        if "××œ××™ × ××•×š" in answer and role == "Supplier":
            answer += "\nğŸ”— ×¤×¢×•×œ×” ××”×™×¨×”: ×ª×¤×¨×™×˜ > ××•×¦×¨×™× > ×¢×“×›×•×Ÿ ××œ××™"
        
        elif "×”×–×× ×”" in answer and "×—×“×©×”" in question.lower():
            if role == "StoreOwner":
                answer += "\nğŸ”— ×™×¦×™×¨×ª ×”×–×× ×”: ×ª×¤×¨×™×˜ > ×”×–×× ×•×ª > ×”×–×× ×” ×—×“×©×”"
        
        elif "×™×™×¦×•×" in answer or "×“×•×—" in answer:
            answer += "\nğŸ”— ×™×™×¦×•× ××”×™×¨: ×ª×¤×¨×™×˜ > ×“×•×—×•×ª > ×™×™×¦×•× × ×ª×•× ×™×"
        
        # ×”×•×¡×£ ×¡×˜×˜×™×¡×˜×™×§×” ×¨×œ×•×•× ×˜×™×ª
        kpis = context.get("kpis", {})
        if "××•×¦×¨×™×" in answer and role == "Supplier":
            total_stock = kpis.get('total_stock', 0)
            if total_stock > 0:
                answer += f"\nğŸ“Š ××™×“×¢ × ×•×¡×£: {total_stock} ×™×—×™×“×•×ª ×‘××œ××™ ×›×•×œ×œ"
        
        return answer

    def get_context_for_api(self, user_id: int) -> Optional[Dict]:
        """××—×–×™×¨ context ×œ×©×™××•×© ×‘-API"""
        user = self._fetch_user(user_id)
        if not user:
            return None
            
        role = self._resolve_role(user)
        username = getattr(user, "username", "") or getattr(user, "contact_name", "")
        
        # ×‘× ×™×™×ª snapshot ×¢×“×›× ×™
        if role == "Supplier":
            context = build_supplier_context(self.db, user_id)
            snapshot_text = supplier_context_to_text(context)
        else:
            context = build_owner_context(self.db, user_id)
            snapshot_text = owner_context_to_text(context)
        
        return {
            "user_id": user.id,
            "username": username,
            "role": role,
            "snapshot": snapshot_text,
            "full_context": context  # ×œ×©×™××•×© ××ª×§×“×
        }

# ---- Enhanced Chat Suggestions ----
def get_smart_suggestions(db: Session, user_id: int, role: str) -> List[str]:
    """××—×–×™×¨ ×”×¦×¢×•×ª ×©××œ×•×ª ×—×›××•×ª ×‘×”×ª×‘×¡×¡ ×¢×œ ××¦×‘ ×”××©×ª××©"""
    
    if role == "Supplier":
        # ×‘×“×•×§ ××¦×‘ ×”×¡×¤×§ ×•×ª×Ÿ ×”×¦×¢×•×ª ×¨×œ×•×•× ×˜×™×•×ª
        context = build_supplier_context(db, user_id)
        kpis = context.get("kpis", {})
        samples = context.get("samples", {})
        
        suggestions = ["×›××” ××•×¦×¨×™× ×¤×¢×™×œ×™× ×™×© ×œ×™?"]  # ×ª××™×“ ×¨×œ×•×•× ×˜×™
        
        if kpis.get("open_orders_count", 0) > 0:
            suggestions.append("××™×œ×• ×”×–×× ×•×ª ×“×•×¨×©×•×ª ×˜×™×¤×•×œ?")
            suggestions.append("××™×š ×œ×¢×“×›×Ÿ ×¡×˜×˜×•×¡ ×”×–×× ×•×ª?")
        
        if kpis.get("low_stock_count", 0) > 0:
            suggestions.append("××™×œ×• ××•×¦×¨×™× ×‘××œ××™ × ××•×š?")
            suggestions.append("××™×š ×œ×¢×“×›×Ÿ ××œ××™?")
        
        if kpis.get("total_revenue", 0) > 0:
            suggestions.append("××™×œ×• ×”××•×¦×¨×™× ×”×›×™ ×¨×•×•×—×™×™× ×©×œ×™?")
            suggestions.append("×›××” ×”×¨×•×•×—×ª×™ ×”×—×•×“×©?")
        
        suggestions.extend([
            "××™×š ×œ×”×•×¡×™×£ ××•×¦×¨ ×—×“×©?",
            "××™×š ×œ×™×™×¦× ×“×•×— ×”×–×× ×•×ª?",
            "×›××” ×—×™×‘×•×¨×™× ×¤×¢×™×œ×™× ×™×© ×œ×™?"
        ])
        
    else:  # StoreOwner
        context = build_owner_context(db, user_id)
        kpis = context.get("kpis", {})
        
        suggestions = ["××” ×”××¦×‘ ×©×œ ×”×”×–×× ×•×ª ×©×œ×™?"]  # ×ª××™×“ ×¨×œ×•×•× ×˜×™
        
        if kpis.get("open_orders_count", 0) > 0:
            suggestions.append("××ª×™ ×ª×’×™×¢ ×”×”×–×× ×” ×©×œ×™?")
            suggestions.append("××” ×¡×˜×˜×•×¡ ×”×”×–×× ×•×ª ×”×¤×ª×•×—×•×ª?")
        
        if kpis.get("orders_total", 0) > 0:
            suggestions.append("×××™×–×” ×¡×¤×§ ×›×“××™ ×œ×”×–××™×Ÿ?")
            suggestions.append("×›××” ×”×•×¦××ª×™ ×”×—×•×“×©?")
            suggestions.append("××™×š ×œ×”×–××™×Ÿ ×©×•×‘ ××ª ××•×ª× ××•×¦×¨×™×?")
        
        suggestions.extend([
            "××™×š ×œ×™×¦×•×¨ ×”×–×× ×” ×—×“×©×”?",
            "××™×š ×œ×—×¤×© ×¡×¤×§×™× ×—×“×©×™×?",
            "××™×š ×œ×™×™×¦× ×“×•×— ×”×•×¦××•×ª?"
        ])
    
    return suggestions[:8]  # ××’×‘×™×œ ×œ××¡×¤×¨ ×¡×‘×™×¨

# ---- API Functions ×”××—×œ×™×¤×•×ª ××ª ×”×§×‘×¦×™× ×”×™×©× ×™× ----

def answer_question(db: Session, question: str, user_id: int) -> str:
    """×”×ª×—×œ×™×£ ×”×—×›× ×œ-answer_question ×”××§×•×¨×™"""
    service = SmartAIService(db)
    return service.get_smart_answer(question, user_id)

def get_context(db: Session, user_id: int) -> Optional[Dict]:
    """×”×ª×—×œ×™×£ ×”×—×›× ×œ-get_context ×”××§×•×¨×™"""
    service = SmartAIService(db)
    return service.get_context_for_api(user_id)

def build_prompt(role: str, username: str, ctx_text: str, question: str) -> str:
    """×”×ª×—×œ×™×£ ×”×—×›× ×œ-build_prompt ×”××§×•×¨×™ ×œ×©×™××•×© streaming"""
    # ×¤×¨×•××¤×˜ ××§×•×¦×¨ ×œstreaming (×œ× ×›×œ ×”-context)
    role_he = "×¡×¤×§" if role == "Supplier" else "×‘×¢×œ ×—× ×•×ª"
    
    return f"""××ª/×” Supi, ×¢×•×–×¨ AI ×—×›× ×œ-{role_he} ×‘×©× {username}.

×¢×§×¨×•× ×•×ª ×ª×©×•×‘×”:
- ×¢× ×” ×‘×¢×‘×¨×™×ª, ×§×¦×¨ ×•××“×•×™×§
- ×”×ª×—×œ ×‘×ª×©×•×‘×” ×™×©×™×¨×”
- ×”×•×¡×£ ×”××œ×¦×•×ª ××¢×©×™×•×ª
- ×”×©×ª××© ×‘××™×“×¢ ×”××“×•×™×§ ××”××¢×¨×›×ª

××™×“×¢ ×¢×“×›× ×™:
{ctx_text[:800]}...

×©××œ×”: {question}

×ª×©×•×‘×”:"""

# ---- Testing and Validation ----

def test_smart_ai_responses(db: Session, user_id: int) -> Dict[str, str]:
    """×‘×“×™×§×ª ××™×›×•×ª ×ª×©×•×‘×•×ª ×”××¢×¨×›×ª ×”×—×“×©×”"""
    service = SmartAIService(db)
    user = service._fetch_user(user_id)
    if not user:
        return {"error": "××©×ª××© ×œ× × ××¦×"}
    
    role = service._resolve_role(user)
    
    test_questions = {
        "basic_count": "×›××” ××•×¦×¨×™× ×¤×¢×™×œ×™× ×™×© ×œ×™?" if role == "Supplier" else "×›××” ×”×–×× ×•×ª ×™×© ×œ×™?",
        "status_check": "××™×œ×• ×”×–×× ×•×ª ×¤×ª×•×—×•×ª ×™×©?",
        "how_to": "××™×š ×œ×¢×“×›×Ÿ ××œ××™?" if role == "Supplier" else "××™×š ×œ×™×¦×•×¨ ×”×–×× ×”?",
        "analytics": "××” ×”××¦×‘ ×”×¢×¡×§×™ ×©×œ×™?"
    }
    
    results = {}
    for test_name, question in test_questions.items():
        try:
            start_time = time.time()
            answer = service.get_smart_answer(question, user_id)
            response_time = time.time() - start_time
            results[test_name] = f"[{response_time:.2f}s] {answer}"
        except Exception as e:
            results[test_name] = f"ERROR: {str(e)}"
    
    return results

# ---- Migration Helper ----

def migrate_to_smart_ai(db: Session) -> Dict[str, Any]:
    """×¢×•×–×¨ ×œ××¢×‘×¨ ×œ××¢×¨×›×ª ×”×—×“×©×”"""
    try:
        # ×‘×“×™×§×ª ×ª×§×™× ×•×ª ×”×˜×‘×œ××•×ª ×”× ×“×¨×©×•×ª
        required_tables = ["users", "products", "orders", "order_items", "owner_supplier_links"]
        
        for table in required_tables:
            try:
                result = db.execute(f"SELECT COUNT(*) FROM {table}").scalar()
                print(f"âœ… {table}: {result} ×¨×©×•××•×ª")
            except Exception as e:
                print(f"âŒ {table}: ×©×’×™××” - {e}")
                return {"success": False, "error": f"×˜×‘×œ×” {table} ×œ× ×–××™× ×”"}
        
        # ×‘×“×™×§×ª ××•×“×œ AI
        try:
            test_prompt = "Test prompt"
            service = SmartAIService(db)
            response = service._ollama_generate_smart(test_prompt)
            ai_status = "×¤×•×¢×œ" if response else "×œ× ××’×™×‘"
        except Exception as e:
            ai_status = f"×©×’×™××”: {str(e)}"
        
        # ×‘×“×™×§×ª ××©×ª××©×™ ×“××•
        supplier_count = db.query(User).filter(User.userType == "Supplier").count()
        owner_count = db.query(User).filter(User.userType == "StoreOwner").count()
        
        return {
            "success": True,
            "database_status": "×ª×§×™×Ÿ",
            "ai_model_status": ai_status,
            "users": {
                "suppliers": supplier_count,
                "owners": owner_count
            },
            "tables_verified": len(required_tables),
            "migration_complete": True
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

# ---- Advanced Analytics Functions ----

def get_business_insights(db: Session, user_id: int, role: str) -> Dict[str, Any]:
    """××—×–×™×¨ ×ª×•×‘× ×•×ª ×¢×¡×§×™×•×ª ××ª×§×“××•×ª"""
    insights = {
        "recommendations": [],
        "alerts": [],
        "opportunities": []
    }
    
    if role == "Supplier":
        context = build_supplier_context(db, user_id)
        kpis = context.get("kpis", {})
        samples = context.get("samples", {})
        
        # ×”××œ×¦×•×ª ×œ×¡×¤×§
        if kpis.get("low_stock_count", 0) > 0:
            insights["alerts"].append(f"âš ï¸ {kpis['low_stock_count']} ××•×¦×¨×™× ×‘××œ××™ × ××•×š")
            insights["recommendations"].append("×¢×“×›×Ÿ ××œ××™ ××•×¦×¨×™× ×¤×•×¤×•×œ×¨×™×™× ×œ×¤× ×™ ×©× ×’××¨×™×")
        
        if kpis.get("open_orders_count", 0) > 3:
            insights["alerts"].append(f"ğŸ”” {kpis['open_orders_count']} ×”×–×× ×•×ª ×××ª×™× ×•×ª ×œ×˜×™×¤×•×œ")
            insights["recommendations"].append("×¢×“×›×Ÿ ×¡×˜×˜×•×¡ ×”×–×× ×•×ª ×œ×©×™×¤×•×¨ ×©×‘×™×¢×•×ª ×¨×¦×•×Ÿ ×œ×§×•×—×•×ª")
        
        # ×–×™×”×•×™ ×”×–×“×× ×•×™×•×ª
        top_products = samples.get("top_products", [])
        if top_products:
            best_seller = top_products[0]
            if best_seller.get("revenue", 0) > 500:
                insights["opportunities"].append(f"××•×¦×¨ ××•×‘×™×œ: {best_seller['name']} - ×›×“××™ ×œ×”×¨×—×™×‘ ××œ××™")
        
    else:  # StoreOwner
        context = build_owner_context(db, user_id)
        kpis = context.get("kpis", {})
        analytics = context.get("analytics", {})
        
        # ×”××œ×¦×•×ª ×œ×‘×¢×œ ×—× ×•×ª
        if kpis.get("open_orders_count", 0) > 0:
            insights["alerts"].append(f"ğŸ“¦ {kpis['open_orders_count']} ×”×–×× ×•×ª ×‘×¢×™×‘×•×“")
        
        avg_order = analytics.get("average_order_value", 0)
        if avg_order < 100:
            insights["recommendations"].append("×©×§×•×œ ××™×—×•×“ ×”×–×× ×•×ª ×œ×—×™×¡×›×•×Ÿ ×‘×”×•×¦××•×ª ××©×œ×•×—")
        
        # ×–×™×”×•×™ ×¡×¤×§×™× ×˜×•×‘×™×
        supplier_perf = samples.get("supplier_performance", [])
        if supplier_perf:
            best_supplier = supplier_perf[0]
            if best_supplier.get("completion_rate", 0) > 90:
                insights["opportunities"].append(f"×¡×¤×§ ××•××œ×¥: {best_supplier['name']} - ×©×™×¨×•×ª ××¢×•×œ×”")
    
    return insights

# ---- Export Functions for Router Integration ----

def get_enhanced_suggestions(db: Session, user_id: int) -> List[str]:
    """××—×–×™×¨ ×”×¦×¢×•×ª ×©××œ×•×ª ×—×›××•×ª ×œ××©×ª××©"""
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        return ["×œ× × ××¦× ××©×ª××©"]
    
    role = SmartAIService(db)._resolve_role(user)
    return get_smart_suggestions(db, user_id, role)

def get_business_dashboard(db: Session, user_id: int) -> Dict[str, Any]:
    """××—×–×™×¨ ×œ×•×— ×‘×§×¨×” ×¢×¡×§×™ ××œ×"""
    service = SmartAIService(db)
    user = service._fetch_user(user_id)
    if not user:
        return {"error": "××©×ª××© ×œ× × ××¦×"}
    
    role = service._resolve_role(user)
    context = service.get_context_for_api(user_id)
    insights = get_business_insights(db, user_id, role)
    suggestions = get_smart_suggestions(db, user_id, role)
    
    return {
        "user_info": {
            "id": user_id,
            "username": getattr(user, "username", ""),
            "role": role
        },
        "context": context,
        "insights": insights,
        "suggested_questions": suggestions,
        "last_updated": time.time()
    }

# ---- Performance Monitoring ----

class AIPerformanceMonitor:
    """××•× ×™×˜×•×¨ ×‘×™×¦×•×¢×™ ×”××¢×¨×›×ª ×”×—×“×©×”"""
    
    def __init__(self):
        self.response_times = []
        self.cache_hits = 0
        self.cache_misses = 0
        self.intent_hits = 0
        self.ai_calls = 0
    
    def log_response_time(self, time_ms: float):
        self.response_times.append(time_ms)
        if len(self.response_times) > 100:
            self.response_times.pop(0)
    
    def log_cache_hit(self):
        self.cache_hits += 1
    
    def log_cache_miss(self):
        self.cache_misses += 1
    
    def log_intent_hit(self):
        self.intent_hits += 1
    
    def log_ai_call(self):
        self.ai_calls += 1
    
    def get_stats(self) -> Dict[str, Any]:
        if not self.response_times:
            return {"status": "××™×Ÿ × ×ª×•× ×™× ×¢×“×™×™×Ÿ"}
        
        avg_time = sum(self.response_times) / len(self.response_times)
        cache_rate = self.cache_hits / (self.cache_hits + self.cache_misses) if (self.cache_hits + self.cache_misses) > 0 else 0
        intent_rate = self.intent_hits / (self.intent_hits + self.ai_calls) if (self.intent_hits + self.ai_calls) > 0 else 0
        
        return {
            "average_response_time_ms": round(avg_time, 2),
            "cache_hit_rate": f"{cache_rate:.1%}",
            "intent_resolution_rate": f"{intent_rate:.1%}",
            "total_queries": len(self.response_times)
        }

# ×™×¦×™×¨×ª monitor ×’×œ×•×‘×œ×™
performance_monitor = AIPerformanceMonitor()

# ---- Updated Router Integration ----

def smart_answer_question(db: Session, question: str, user_id: int) -> str:
    """×”×¤×•× ×§×¦×™×” ×”×¨××©×™×ª ×”×—×“×©×” - ××—×œ×™×¤×” ××ª answer_question ×”×™×©× ×”"""
    start_time = time.time()
    
    try:
        service = SmartAIService(db)
        answer = service.get_smart_answer(question, user_id)
        
        response_time = (time.time() - start_time) * 1000
        performance_monitor.log_response_time(response_time)
        
        return answer
        
    except Exception as e:
        return f"×©×’×™××” ×‘××¢×¨×›×ª AI: {str(e)}\n× ×¡×” ×œ×©××•×œ ×©××œ×” ×¤×©×•×˜×” ×™×•×ª×¨."

def smart_get_context(db: Session, user_id: int) -> Optional[Dict]:
    """×”×¤×•× ×§×¦×™×” ×”×—×“×©×” ×œ×§×‘×œ×ª context - ××—×œ×™×¤×” ××ª get_context ×”×™×©× ×”"""
    service = SmartAIService(db)
    return service.get_context_for_api(user_id)

# ---- Easy Migration Functions ----

def migrate_existing_ai_service():
    """×”×“×¨×›×” ×œ××¢×‘×¨ ×œ××¢×¨×›×ª ×”×—×“×©×”"""
    return """
ğŸ”„ ××¢×‘×¨ ×œ××¢×¨×›×ª AI ×”×—×›××”:

1. ×”×—×œ×£ ×‘-ai_router.py:
   from services.ai_service import answer_question, get_context
   â†“
   from services.smart_ai_integration import smart_answer_question as answer_question, smart_get_context as get_context

2. ×”×—×œ×£ ×‘-ai_service.py:
   # ×”×¢×‘×¨ ××ª ×”×§×•×‘×¥ ×”×™×©×Ÿ ×œ-ai_service_old.py
   # ×”×©×ª××© ×‘-smart_ai_integration.py ×‘××§×•×

3. ×¢×“×›×Ÿ requirements.txt (×× × ×“×¨×©):
   # ××™×Ÿ ×ª×œ×•×™×•×ª ×—×“×©×•×ª - ×”×›×œ ×¢×•×‘×“ ×¢× ×”××¢×¨×›×ª ×”×§×™×™××ª

4. ×‘×“×™×§×ª ×ª×§×™× ×•×ª:
   python -c "from services.smart_ai_integration import migrate_to_smart_ai; print('âœ… ×”××¢×¨×›×ª ×”×—×“×©×” ××•×›× ×”!')"

×”××¢×¨×›×ª ×”×—×“×©×” ×ª×¡×¤×§:
- ×ª×©×•×‘×•×ª ×™×•×ª×¨ ×—×›××•×ª ×•××“×•×™×§×•×ª
- ×–×™×›×¨×•×Ÿ ×œ-45 ×©× ×™×•×ª ×œ×‘×™×¦×•×¢×™× ×˜×•×‘×™×
- ×–×™×”×•×™ ××ª×§×“× ×©×œ ×›×•×•× ×•×ª ××©×ª××©  
- ×”××œ×¦×•×ª ×¢×¡×§×™×•×ª ××•×˜×•××˜×™×•×ª
- × ×™×ª×•×— ×‘×™×¦×•×¢×™× ×‘×–××Ÿ ×××ª
"""