# backend/routers/ai_router.py - 注 endpoints  砖
from fastapi import APIRouter, Depends, HTTPException
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
import httpx, json, os

from database.session import get_db
from schemas.ai import AIAskRequest, AIAnswer, AIContext

#  注专转  砖
from services.smart_ai_integration import (
    smart_answer_question as answer_question, 
    smart_get_context as get_context,
    get_enhanced_suggestions,
    get_business_dashboard,
    get_business_insights,
    performance_monitor
)

router = APIRouter(prefix="/ai", tags=["ai"])

OLLAMA = os.getenv("OLLAMA_URL", "http://localhost:11434")
MODEL = os.getenv("OLLAMA_MODEL", "mistral:7b-instruct")

# ---- Endpoints 住住 砖驻专 ----

@router.post("/ask", response_model=AIAnswer)
def ai_ask(payload: AIAskRequest, db: Session = Depends(get_db)):
    """砖  注 注专转 转拽转"""
    ans = answer_question(db, payload.question, payload.user_id)
    return AIAnswer(answer=ans)

@router.get("/context", response_model=AIContext)
def ai_context(user_id: int, db: Session = Depends(get_db)):
    """context 注砖专 注 注专转 砖"""
    ctx = get_context(db, user_id)
    if not ctx:
        raise HTTPException(status_code=404, detail="User not found")
    return AIContext(**ctx)

# ---- Endpoints  砖 ----

@router.get("/smart-suggestions")
def get_smart_suggestions(user_id: int, db: Session = Depends(get_db)):
    """爪注转 砖转 转 转住住 注 爪 砖转砖"""
    try:
        suggestions = get_enhanced_suggestions(db, user_id)
        return {
            "user_id": user_id,
            "suggestions": suggestions,
            "count": len(suggestions),
            "generated_at": "now"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating suggestions: {str(e)}")

@router.get("/business-insights")
def get_business_insights_endpoint(user_id: int, db: Session = Depends(get_db)):
    """转转 注住拽转 转"""
    try:
        # 拽  转 role 砖 砖转砖
        from services.smart_ai_integration import SmartAIService
        service = SmartAIService(db)
        user = service._fetch_user(user_id)
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        
        role = service._resolve_role(user)
        insights = get_business_insights(db, user_id, role)  # 砖转砖 专ole 转
        
        return {
            "user_id": user_id,
            "insights": insights,
            "generated_at": "now"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating insights: {str(e)}")

@router.get("/dashboard")
def get_smart_dashboard(user_id: int, db: Session = Depends(get_db)):
    """ 拽专  """
    try:
        dashboard = get_business_dashboard(db, user_id)
        return dashboard
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generating dashboard: {str(e)}")

@router.get("/performance")
def get_ai_performance():
    """住住拽转 爪注 注专转"""
    return {
        "performance": performance_monitor.get_stats(),
        "system_status": "operational",
        "model": MODEL,
        "version": "2.0-smart"
    }

# ---- Streaming 砖驻专 ----

@router.get("/stream")
async def ai_stream_enhanced(question: str, user_id: int, db: Session = Depends(get_db)):
    ctx = get_context(db, user_id)
    if not ctx:
        raise HTTPException(status_code=404, detail="User not found")

    from services.smart_ai_integration import smart_get_context, smart_answer_question
    full_context = smart_get_context(db, user_id)
    snapshot = full_context.get("snapshot", "")

    prompt = f"""转 Supi, 注专 AI  注专转  住驻拽.
砖转砖: {ctx['username']} ({ctx['role']})

注 注 注专转:
{snapshot[:1200]}

砖: {question}

注 注专转,  注砖 注 爪转 拽拽专转:"""

    async def generate_smart_stream():
        emitted = False
        try:
            async with httpx.AsyncClient(timeout=None) as client:
                async with client.stream(
                    "POST", f"{OLLAMA}/api/generate",
                    json={
                        "model": MODEL,
                        "prompt": prompt,
                        "stream": True,
                        "options": {
                            "num_predict": 256,
                            "num_ctx": 4096,
                            "temperature": 0.3,
                            "top_p": 0.85,
                            "repeat_penalty": 1.15
                        }
                    }
                ) as r:
                    async for line in r.aiter_lines():
                        if not line:
                            continue
                        try:
                            obj = json.loads(line)
                            chunk = obj.get("response", "")
                            if chunk:
                                emitted = True
                                yield chunk
                        except:
                            continue
        except Exception:
            # 驻 -plan B  专 砖
            emitted = False

        if not emitted:
            # Fallback: 转砖 -住专  
            try:
                ans = smart_answer_question(db, question, user_id)
                yield (ans or " 注")
            except Exception:
                yield " 注"
        else:
            # 专拽  转  转 , 住祝  砖 注
            yield "\n\n 砖 注 砖转? 专 爪注转 转 爪!"

    return StreamingResponse(generate_smart_stream(), media_type="text/plain; charset=utf-8")


# ---- Testing Endpoints ----

@router.get("/test/smart-system")
def test_smart_system(user_id: int = 1, db: Session = Depends(get_db)):
    """拽转 转拽转 注专转 """
    try:
        from services.smart_ai_integration import test_smart_ai_responses
        
        results = test_smart_ai_responses(db, user_id)
        return {
            "system_status": "smart system operational",
            "test_results": results,
            "performance": performance_monitor.get_stats()
        }
    except Exception as e:
        return {
            "system_status": "error",
            "error": str(e)
        }

# ---- Migration Helper Endpoint ----

@router.post("/migrate-to-smart")
def migrate_to_smart_system(db: Session = Depends(get_db)):
    """endpoint 爪注 注专 注专转 """
    try:
        from services.smart_ai_integration import migrate_to_smart_ai
        
        result = migrate_to_smart_ai(db)
        return {
            "migration_status": "completed" if result.get("success") else "failed",
            "details": result,
            "next_steps": [
                "拽 砖endpoints 砖 注",
                "注 转 frontend 砖转砖 tabs 砖", 
                "拽 砖爪注转 转 驻注转"
            ] if result.get("success") else ["转拽 转 注转 住 砖"]
        }
    except Exception as e:
        return {
            "migration_status": "failed",
            "error": str(e)
        }