# docker-compose.ultra-fast.yml - Docker Compose ×××•×¤×˜× ×œ××”×™×¨×•×ª ××§×¡×™××œ×™×ª
version: '3.8'

services:
  ollama-ultra:
    image: ollama/ollama:latest
    container_name: ollama_ultra_fast
    ports:
      - "11434:11434"
    volumes:
      - ollama_ultra_data:/root/.ollama
    environment:
      # ××•×¤×˜×™××™×–×¦×™×•×ª ××”×™×¨×•×ª ××§×¡×™××œ×™×ª
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_LOW_VRAM=true
      - OLLAMA_KEEP_ALIVE=5m
      - OLLAMA_MAX_QUEUE=2
      - OLLAMA_CONCURRENCY=1
      # ×”×’×“×¨×•×ª ×–×™×›×¨×•×Ÿ
      - OLLAMA_MAX_VRAM=1GB
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G  # ×”×’×‘×œ×ª ×–×™×›×¨×•×Ÿ
        reservations:
          memory: 1G
    # GPU support (×”×¡×¨ comment ×× ×™×© GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ×©×™×¨×•×ª ××ª×—×•×œ ××•×“×œ×™×
  ollama-setup:
    image: curlimages/curl:latest
    container_name: ollama_model_setup
    depends_on:
      ollama-ultra:
        condition: service_healthy
    volumes:
      - ./setup_models.sh:/setup_models.sh:ro
    command: |
      sh -c "
        echo 'ğŸš€ ××ª×—×™×œ ×”×ª×§× ×ª ××•×“×œ×™×...'
        
        # ×”××ª×Ÿ ×©Ollama ×™×”×™×” ××•×›×Ÿ
        for i in \$$(seq 1 30); do
          if curl -s http://ollama-ultra:11434/api/version >/dev/null; then
            echo 'âœ… Ollama ××•×›×Ÿ!'
            break
          fi
          echo '×××ª×™×Ÿ ×œOllama... (\$$i/30)'
          sleep 2
        done
        
        # ×”×ª×§×Ÿ ××•×“×œ×™× ×§×œ×™×
        echo 'â¬‡ï¸ ××ª×§×™×Ÿ ××•×“×œ qwen2.5:0.5b...'
        curl -X POST http://ollama-ultra:11434/api/pull \
          -H 'Content-Type: application/json' \
          -d '{\"name\":\"qwen2.5:0.5b\"}'
          
        echo 'â¬‡ï¸ ××ª×§×™×Ÿ ××•×“×œ tinyllama ×—×œ×•×¤×™...'
        curl -X POST http://ollama-ultra:11434/api/pull \
          -H 'Content-Type: application/json' \
          -d '{\"name\":\"tinyllama\"}'
          
        echo 'âœ… ×”×ª×§× ×ª ××•×“×œ×™× ×”×•×©×œ××”!'
        
        # ×‘×“×™×§×”
        curl -X POST http://ollama-ultra:11434/api/generate \
          -H 'Content-Type: application/json' \
          -d '{\"model\":\"qwen2.5:0.5b\",\"prompt\":\"×©×œ×•×\",\"stream\":false}' | head -c 200
          
        echo 'ğŸ‰ ×”×›×œ ××•×›×Ÿ!'
      "
    restart: "no"

volumes:
  ollama_ultra_data:
    driver: local

networks:
  default:
    name: ollama_ultra_network